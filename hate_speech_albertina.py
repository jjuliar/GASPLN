# -*- coding: utf-8 -*-
"""CÃ³pia de Base_For_IronyDetection_Albertina.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oWGrNh7dD8YxIeZuV35Pz4v6Swu8lA0q
"""

# Transformers installation


import numpy as np
import evaluate
import gdown
import pandas as pd
import torch
from sklearn.metrics import *
from datasets import load_dataset
from transformers import AutoTokenizer, DataCollatorWithPadding, AutoModelForSequenceClassification
from transformers import TrainingArguments, Trainer
from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler

"""## Loading dataset"""

# imdb = load_dataset("imdb")
url = "https://drive.google.com/file/d/1hRkZGCbyBH7D58pJkz47ZczZQe_IRDib/view?usp=sharing"
output = "toldbrbinariosemduplicadas.csv"
gdown.download(url, output, quiet=False, fuzzy=True)

# url2 = "https://drive.google.com/file/d/1386svaKYa2_b3zPLBjmOzIVbOLH4ZurY/view?usp=sharing"
# output2 = "test_tweets.csv"
# gdown.download(url2, output2, quiet=False, fuzzy=True)

#Test
from datasets import Dataset, DatasetDict

# train_dataset = load_dataset("csv", data_files='/content/treino_tweets.csv', delimiter='\t')
# test_dataset = load_dataset("csv", data_files='/content/test_tweets.csv', delimiter='\t')

dataset = pd.read_csv('/home/jjuliar/qanda/toldbrbinariosemduplicadas.csv', delimiter = ',')


dataset = dataset.drop(columns=['Unnamed: 0','homophobia_1',	'homophobia_2',	'homophobia_3',	'obscene_1',	'obscene_2',	'obscene_3',	'insult_1',	'insult_2',	'insult_3','racism_1',	'racism_2',
                     'racism_3',	'misogyny_1',	'misogyny_2',	'misogyny_3',	'xenophobia_1',	'xenophobia_2',	'xenophobia_3', 'obs_1',	'obs_2',	'obs_3',
                     'toxic_1',	'toxic_2',	'toxic_3',	'homophobia',	'obscene',	'insult',	'racism', 'misogyny',	'xenophobia'])
# tdf = pd.DataFrame({"a": [1, 2, 3], "b": ['hello', 'ola', 'thammi']})
# vdf = pd.DataFrame({"a": [4, 5, 6], "b": ['four', 'five', 'six']})


tds = Dataset.from_pandas(dataset)
tds = tds.train_test_split(test_size=0.1)

ds = DatasetDict()
ds = tds

print(ds)

"""## Preprocess"""

tokenizer = AutoTokenizer.from_pretrained("/home/jjuliar/qanda/Felixbot")

def preprocess_function(examples):
    return tokenizer(examples["text"], padding="max_length", truncation=True)

tokenized_dataset = ds.map(preprocess_function, batched=True)

tokenized_dataset = tokenized_dataset.rename_columns({'toxic' : 'labels'})

data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

"""## Evaluate"""

accuracy = evaluate.load("accuracy")
tokenized_dataset

"""Then create a function that passes your predictions and labels to [compute](https://huggingface.co/docs/evaluate/main/en/package_reference/main_classes#evaluate.EvaluationModule.compute) to calculate the accuracy:"""

# def compute_metrics(eval_pred):
#     predictions, labels = eval_pred
#     predictions = np.argmax(predictions, axis=1)
#     eval_comb = evaluate.combine(["accuracy", "f1", "precision", "recall"])
#     return eval_comb.compute(predictions=predictions, references=labels)

accuracy =  evaluate.load("accuracy")
recall =  evaluate.load("recall")
f1 =  evaluate.load("f1")
precision =  evaluate.load("precision")
def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    predictions = np.argmax(predictions, axis=1)
    
    results = []
    results.append(f1.compute(predictions=predictions, references = labels, average= "weighted"))
    results.append(precision.compute(predictions=predictions, references = labels, average= "weighted"))
    results.append(recall.compute(predictions=predictions, references = labels, average= "weighted"))
    results.append(accuracy.compute(predictions=predictions, references = labels, ))
    print(results)
    return results

eval_comb = evaluate.combine(["accuracy", "f1", "precision", "recall"])


"""Your `compute_metrics` function is ready to go now, and you'll return to it when you setup your training.

## Training

Before you start training your model, create a map of the expected ids to their labels with `id2label` and `label2id`:
"""



model = AutoModelForSequenceClassification.from_pretrained(
    "/home/jjuliar/qanda/Felixbot", num_labels=2
)

training_args = TrainingArguments(
    output_dir="Felixbot",
    learning_rate=1e-5,
    per_device_train_batch_size=2,
    per_device_eval_batch_size=2,
    num_train_epochs=1,
    weight_decay=0.01,
    evaluation_strategy="epoch",
    save_strategy="epoch",
    load_best_model_at_end=True,
    push_to_hub=False,
    fp16=True,
    label_names = ["labels"],
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_dataset["train"],
    eval_dataset=tokenized_dataset["test"],
    tokenizer=tokenizer,
    data_collator=data_collator,
    compute_metrics=compute_metrics,
)

# trainer.train()

# trainer.save_model("Felixbot")


"""## Inference"""

classifier = pipeline("text-classification", model="/home/jjuliar/qanda/Felixbot")
classifier

"""##Results

"""


predictions = trainer.predict(tokenized_dataset["test"])
print(predictions.predictions.shape, predictions.label_ids.shape)
print(predictions)


# preds = np.argmax(predictions.predictions, axis=1)
# metric = evaluate.load("glue", "mrpc")

# print(metric.compute(predictions=preds, references=predictions.label_ids))

from evaluate import evaluator

task_evaluator = evaluator("text-classification")

eval_results = task_evaluator.compute(
    model_or_pipeline=classifier,
    data=tokenized_dataset['test'],
    metric=eval_comb,
    label_mapping={"LABEL_0": 0, "LABEL_1": 1},
    label_column = 'labels',
)

print(eval_results)

