# -*- coding: utf-8 -*-
"""AlBERTina ABSA and AR.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/127SXLJPNS0SyqbYig8-QnC5edoQyjRSK

https://huggingface.co/PORTULAN/albertina-ptbr
"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !pip install transformers
# !pip install datasets
# !pip install accelerate
# !pip install transformers[torch]
# !pip install sentencepiece
import gdown
import evaluate
import pandas as pd
from datasets import load_dataset
from transformers import AutoTokenizer, DataCollatorWithPadding, AutoModelForSequenceClassification
from transformers import TrainingArguments, Trainer
from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler

url = "https://drive.google.com/file/d/1n5oz2GzA8uNK0Xg-s91YjZIw9BPJpnGB/view?usp=drive_link"
output = "df_test.csv"
gdown.download(url, output, quiet=False, fuzzy=True)

url2 = "https://drive.google.com/file/d/1r4ZuOdFI9NTuj6Eicc5j_Ls7oTuDTHzy/view?usp=drive_link"
output2 = "df_train.csv"
gdown.download(url2, output2, quiet=False, fuzzy=True)

df_train = pd.read_csv('/home/jjuliar/qanda/df_train.csv', sep=';')
df_test = pd.read_csv('/home/jjuliar/qanda/df_test.csv', sep=';')
df_train.head()

df_test.head()

print(df_test)
aux = df_train['aspect'].value_counts() > 20
filter = set(aux[aux == True].keys())
aux = df_train[df_train['aspect'].isin(filter)]
aux0 = df_test[df_test['aspect'].isin(filter)]

train_ids = aux['id'].values
train_sentencas = aux['review'].values
train_labels = aux['aspect'].values

test_ids = aux0['id'].values
test_sentencas = aux0['review'].values
test_labels = aux0['aspect'].values

ont = {}
count = 0
for i in set(train_labels):
  ont[i] = count
  count += 1

import numpy as np

for i in range(len(train_labels)):
  if train_labels[i] in ont:
    train_labels[i] = int(ont[train_labels[i]])
train_labels = np.array(train_labels, dtype = int)

for i in range(len(test_labels)):
  if test_labels[i] in ont:
    test_labels[i] = int(ont[test_labels[i]])
test_labels = np.array(test_labels, dtype = int)

import torch

device = 0
if torch.cuda.is_available():

    # Tell PyTorch to use the GPU.
    device = torch.device("cuda")

    print('There are %d GPU(s) available.' % torch.cuda.device_count())

    print('We will use the GPU:', torch.cuda.get_device_name(0))

# If not...
else:
    print('No GPU available, using the CPU instead.')
    device = torch.device("cpu")

# Commented out IPython magic to ensure Python compatibility.
from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer
from transformers import DebertaTokenizer

model = AutoModelForSequenceClassification.from_pretrained("PORTULAN/albertina-ptbr-base", num_labels = 25)
tokenizer = DebertaTokenizer.from_pretrained("microsoft/deberta-base")
# tokenizer("Isso Ã© um teste")["input_ids"]

model.cuda()

from datasets import Dataset, DatasetDict

tdf = pd.DataFrame({"review": train_sentencas, "label": train_labels, "idx": train_ids})
vdf = pd.DataFrame({"review": test_sentencas, "label": test_labels, "idx": test_ids})
tds = Dataset.from_pandas(tdf)
vds = Dataset.from_pandas(vdf)

dataset = DatasetDict()

dataset['train'] = tds
dataset['validation'] = vds

def tokenize_function(examples):
    return tokenizer(examples["review"], padding="max_length", truncation=True)

tokenized_datasets = dataset.map(tokenize_function, batched=True)
accuracy =  evaluate.load("accuracy")
recall =  evaluate.load("recall")
f1 =  evaluate.load("f1")
precision =  evaluate.load("precision")
def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    predictions = np.argmax(predictions, axis=1)
    
    results = []
    results.append(f1.compute(predictions=predictions, references = labels, average= "weighted"))
    results.append(precision.compute(predictions=predictions, references = labels, average= "weighted"))
    results.append(recall.compute(predictions=predictions, references = labels, average= "weighted"))
    results.append(accuracy.compute(predictions=predictions, references = labels, ))
    print(results)
    return results

# training_args = TrainingArguments(output_dir="albertina-ptbr-rte", evaluation_strategy="epoch")
training_args = TrainingArguments(output_dir = "albertina-ptbr-ae",
    evaluation_strategy = "epoch", fp16 = True,
    learning_rate=1e-5,
    per_device_train_batch_size=2,
    per_device_eval_batch_size=2,
    num_train_epochs=3,
    )

trainer = Trainer(
    model = model,
    args = training_args,
    train_dataset = tokenized_datasets["train"],
    eval_dataset = tokenized_datasets["validation"],
    compute_metrics=compute_metrics,
)

trainer.train()